<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Classification</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/journal.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 61px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h2 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h3 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h4 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h5 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h6 {
  padding-top: 66px;
  margin-top: -66px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">CS 499</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Overview</a>
</li>
<li>
  <a href="Visualization.html">Exploratory Data Analysis</a>
</li>
<li>
  <a href="Regression.html">Regression</a>
</li>
<li>
  <a href="Classification.html">Classification</a>
</li>
<li>
  <a href="blogpost1.html">Blog Post 1</a>
</li>
<li>
  <a href="blogpost2.html">Blog Post 2</a>
</li>
<li>
  <a href="blogpost3.html">Blog Post 3</a>
</li>
<li>
  <a href="blogpost4.html">Blog Post 4</a>
</li>
<li>
  <a href="progress.html">Progress Insight</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Classification</h1>

</div>


<p>Now we will predict whether one client will buy a bike or not based on certain demographic features. The method we’ll use is called DECISION TREE. Decision tress are algorithms of supervised classification, which seek to predict a specific dependent variable (BikeBuyer in this case). Both independent and depedendent variables can be either qualitative or quantitive. If the dependent variable is numerical, we call it “Regression Tree”; but in our case, where the variable is categorical (even if we represent it with O and 1), then we call it CLASSIFICATION TREE. And the end, we’ll compare it to the logistic regression model, which is used to predict binary variables too.</p>
<div id="i.-lets-load-the-libraries-and-dataset." class="section level2">
<h2>I. Let’s load the libraries and dataset.</h2>
<p>Here the new ones are the rpart and rpart.plot libraries used for the creationg of the classification model and graphing the decision tree respectively.</p>
<pre class="r"><code>library(readr)          #to read in the csv
library(dbplyr)         #for data wrangling
library(tidyverse)      #for data wrangling, for example the function &quot;select&quot;
library(rpart)          #decision tree algorithm
library(rpart.plot)     #graph the decision tree</code></pre>
</div>
<div id="ii.-data-wrangle" class="section level2">
<h2>II. Data Wrangle</h2>
<p>The data wrangling part we can see it in the other sections (Regression or Exploratory Data Analysis). The only exception is that we added the column of Bike Buyer(which has 1 if the customer bought a bike, or a 0 if they didn’t) to the data_qualitative subset. That’s the most important column for this part of the analysis.</p>
<pre class="r"><code>customer              &lt;- read_csv(&quot;~/CS 499 Senior Project/datasets/AdvWorksCusts.csv&quot;)
spend                 &lt;- read_csv(&quot;~/CS 499 Senior Project/datasets/AW_AveMonthSpend.csv&quot;)
bikebuyer             &lt;- read_csv(&quot;~/CS 499 Senior Project/datasets/AW_BikeBuyer.csv&quot;)
three_datasets        &lt;- data.frame(customer, spend, bikebuyer)
data_clean            &lt;- select(three_datasets,-c(CustomerID.1, CustomerID.2))
missing_values        &lt;- sapply(data_clean, function(x) sum(is.na(x))) #it checks number of missing values by column
data_clean            &lt;- select(three_datasets,-c(CustomerID.1, CustomerID.2, Title, MiddleName, Suffix, AddressLine2)) 
data_clean            &lt;- data_clean[!duplicated(data_clean), ] #it removes duplicates
###Let&#39;s add up age column using the existing DOB column
#Change BirthDate from Character to Date format
data_clean$BirthDate  &lt;- as.Date(data_clean$BirthDate, format = &quot;%m/%d/%Y&quot;)

#Append the new column called Age
data_clean$Age        &lt;- as.numeric(difftime(&quot;1998-01-01&quot;,data_clean$BirthDate, units = &quot;weeks&quot;))/52.25

data_qualitative      &lt;- data_clean %&gt;% select(11:16,21) 
data_quantitative     &lt;- data_clean %&gt;% select(c(22,17:20))
features              &lt;- cbind(data_quantitative,data_qualitative)
#plot(data_quantitative)</code></pre>
<p>We’ll have to select some features, the ones that correlate the most with the dependent variable. I think it’s easier if we do that separating the independent variables between categorical and numerical. When you plot numerical variables, we can see some correlation with age and average month spent, so we’ll keep those, and get rid of the rest. As for the qualitative variables, we could do some visualizations or Chi Squared test, and explore the possible correlations. For now, let’s just use all possible explanatory variables and then “prune” our decision tree.</p>
</div>
<div id="iii.-now-split-our-traintest-set" class="section level2">
<h2>III. Now split our train/test set</h2>
<p>We’ll divide our dataset this way: 60% train and 40% test. In the first line, we just create an index that we’ll assign 1’s and 2’s to each row, with aprobabibloty of 60/40 %, which in turns gives a vector that we’ll use as “dictionary” to tell which rows will be train and which will be test.</p>
<pre class="r"><code>ind       &lt;- sample(2, nrow(features), replace = TRUE, prob = c(0.6,0.4)) #60% training, 40% test
trainData &lt;- features[ind == 1, ] #training
testData  &lt;- features[ind == 2, ] # test </code></pre>
</div>
<div id="iv.-creation-of-the-decision-tree" class="section level2">
<h2>IV. Creation of the Decision Tree</h2>
<p>We input the dependent variable, and we’ll explain it with a rest of the the variables which is why we leave the space after the Bike buyer, in blank. here “method” indicated that our variable to be predicted is categorical</p>
<pre class="r"><code>tree &lt;- rpart(BikeBuyer ~ ., method = &#39;class&#39;, data = trainData)</code></pre>
</div>
<div id="v.-checking-tree-and-results" class="section level2">
<h2>V. Checking tree and results</h2>
<pre class="r"><code>print(tree)</code></pre>
<pre><code>## n= 9783 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##  1) root 9783 3291 0 (0.6636001 0.3363999)  
##    2) NumberChildrenAtHome&lt; 1.5 7185 1474 0 (0.7948504 0.2051496) *
##    3) NumberChildrenAtHome&gt;=1.5 2598  781 1 (0.3006159 0.6993841)  
##      6) AveMonthSpend&lt; 83.5 812  374 1 (0.4605911 0.5394089)  
##       12) MaritalStatus=M 322  110 0 (0.6583851 0.3416149) *
##       13) MaritalStatus=S 490  162 1 (0.3306122 0.6693878) *
##      7) AveMonthSpend&gt;=83.5 1786  407 1 (0.2278835 0.7721165) *</code></pre>
<pre class="r"><code>rpart.plot(tree, extra = 4)     # extra = 4: probability of observations by class</code></pre>
<p><img src="Classification_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>printcp(tree)                   # stats of results</code></pre>
<pre><code>## 
## Classification tree:
## rpart(formula = BikeBuyer ~ ., data = trainData, method = &quot;class&quot;)
## 
## Variables actually used in tree construction:
## [1] AveMonthSpend        MaritalStatus        NumberChildrenAtHome
## 
## Root node error: 3291/9783 = 0.3364
## 
## n= 9783 
## 
##         CP nsplit rel error  xerror     xstd
## 1 0.314798      0   1.00000 1.00000 0.014200
## 2 0.015497      1   0.68520 0.68520 0.012658
## 3 0.010000      3   0.65421 0.65968 0.012489</code></pre>
<pre class="r"><code>plotcp(tree)                    # evolution of error as the number of nodes increases</code></pre>
<p><img src="Classification_files/figure-html/unnamed-chunk-5-2.png" width="672" /></p>
<p>Here we see that N is the number of observations, 9,808. In the first line, we see that most observations/clients (66.8%) DIDN’T buy a bike (BikeBuyer = 0), and so on. For the company, it’s interesting to see that the person that will likely buy a bike the most is someone who is married, with more than 2 children at home.</p>
</div>
<div id="vi.-pruning-the-tree" class="section level2">
<h2>VI. Pruning the tree</h2>
<pre class="r"><code>pruneTree &lt;- prune(tree, cp = 0.01000) #Using the lowest CP from the printcp(tree) command above
printcp(pruneTree)</code></pre>
<pre><code>## 
## Classification tree:
## rpart(formula = BikeBuyer ~ ., data = trainData, method = &quot;class&quot;)
## 
## Variables actually used in tree construction:
## [1] AveMonthSpend        MaritalStatus        NumberChildrenAtHome
## 
## Root node error: 3291/9783 = 0.3364
## 
## n= 9783 
## 
##         CP nsplit rel error  xerror     xstd
## 1 0.314798      0   1.00000 1.00000 0.014200
## 2 0.015497      1   0.68520 0.68520 0.012658
## 3 0.010000      3   0.65421 0.65968 0.012489</code></pre>
<p>As you can see, printcp(pruneTree) and Tree is the same thus showing that the first command had already pruned (or didn’t) where it had to.</p>
</div>
<div id="vii.-predict-who-will-buy-bikes-on-test-data." class="section level2">
<h2>VII. Predict who will buy bikes on test data.</h2>
<pre class="r"><code>#We validate the ability of prediction of our prediction tree usin the test dataset
testTree &lt;- predict(tree, newdata = testData, type = &#39;class&#39;)

#let&#39;s visualize the results with a matrix of confusion
table(testTree, testData$BikeBuyer)</code></pre>
<pre><code>##         
## testTree    0    1
##        0 4071 1057
##        1  401 1109</code></pre>
<p>There we saw that our model predicted 4,024 people who were not buyers correctly, and 1051 who were did buy but we classifed them as not. Same, with the other row.</p>
</div>
<div id="viii.-evaluating-the-model." class="section level2">
<h2>VIII. Evaluating the model.</h2>
<pre class="r"><code>## Let&#39;s calculate the % of correct answers 
 sum(testTree == testData$BikeBuyer) / length(testData$BikeBuyer)*100</code></pre>
<pre><code>## [1] 78.03555</code></pre>
<p>it shows that we have 78.91% of accurate predictions!</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
